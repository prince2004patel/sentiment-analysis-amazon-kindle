{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLPwgpERVOM",
        "outputId": "f8f2b947-1e23-48f4-ffcf-b7b75959d94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8nxEoaTTZrQ",
        "outputId": "52a10624-3be0-4474-b325-84eedeb732b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/ML/all_kindle_review.csv\")\n",
        "df = dataset[['reviewText', 'rating']]\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Preprocessing\n",
        "df['rating'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)\n",
        "df['reviewText'] = df['reviewText'].str.lower()\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub('[^a-z A-Z 0-9-]+', '', x))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w_-]+(?:\\.[\\w_-]+)+[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-]?', '', x))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], df['rating'], test_size=0.20, random_state=42,stratify=df['rating'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuY7lea_Vytr",
        "outputId": "b3e5fd22-e00b-4432-e21f-b55d1268dc87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8a622369a321>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "<ipython-input-3-8a622369a321>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['rating'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)\n",
            "<ipython-input-3-8a622369a321>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].str.lower()\n",
            "<ipython-input-3-8a622369a321>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: re.sub('[^a-z A-Z 0-9-]+', '', x))\n",
            "<ipython-input-3-8a622369a321>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
            "<ipython-input-3-8a622369a321>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w_-]+(?:\\.[\\w_-]+)+[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-]?', '', x))\n",
            "<ipython-input-3-8a622369a321>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
            "<ipython-input-3-8a622369a321>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n",
            "<ipython-input-3-8a622369a321>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold"
      ],
      "metadata": {
        "id": "WrJz_5RPb4eB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline with BoW\n",
        "pipeline_bow = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Cross-validation\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "cv_scores = cross_val_score(pipeline_bow, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "print(f\"Cross-validation Accuracy: {cv_scores.mean():.2f} Â± {cv_scores.std():.2f}\")\n",
        "\n",
        "# Fit and save the pipeline\n",
        "pipeline_bow.fit(X_train, y_train)\n",
        "with open('/content/drive/MyDrive/ML/pipeline_bow.pkl', 'wb') as file:\n",
        "    pickle.dump(pipeline_bow, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQGFfBiuWMTA",
        "outputId": "f341f2fc-52a0-4300-f078-3a22d674eca4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation Accuracy: 0.83 Â± 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Pipeline with TF-IDF\n",
        "pipeline_tfidf = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "cv_scores = cross_val_score(pipeline_tfidf, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "print(f\"Cross-validation Accuracy: {cv_scores.mean():.2f} Â± {cv_scores.std():.2f}\")\n",
        "\n",
        "pipeline_tfidf.fit(X_train, y_train)\n",
        "\n",
        "# Save the pipeline\n",
        "with open('/content/drive/MyDrive/ML/pipeline_tfidf.pkl', 'wb') as file:\n",
        "    pickle.dump(pipeline_tfidf, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsQqhlbSWxCj",
        "outputId": "059bbef3-0813-4e2f-b687-77c90bcfa14e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation Accuracy: 0.69 Â± 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
        "\n",
        "# Load the BoW pipeline\n",
        "with open('/content/drive/MyDrive/ML/pipeline_bow.pkl', 'rb') as file:\n",
        "    pipeline_bow = pickle.load(file)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_bow = pipeline_bow.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
        "print(f\"BoW Model Accuracy: {accuracy_bow:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix_bow = confusion_matrix(y_test, y_pred_bow)\n",
        "print(\"BoW Confusion Matrix:\")\n",
        "print(conf_matrix_bow)\n",
        "\n",
        "# Classification report\n",
        "report_bow = classification_report(y_test, y_pred_bow)\n",
        "print(\"BoW Classification Report:\")\n",
        "print(report_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O54ryrRSXYqA",
        "outputId": "609d4e32-654b-4ef1-ed78-f2cdc338a2fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Model Accuracy: 0.85\n",
            "BoW Confusion Matrix:\n",
            "[[ 577  223]\n",
            " [ 142 1458]]\n",
            "BoW Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.72      0.76       800\n",
            "           1       0.87      0.91      0.89      1600\n",
            "\n",
            "    accuracy                           0.85      2400\n",
            "   macro avg       0.83      0.82      0.82      2400\n",
            "weighted avg       0.85      0.85      0.85      2400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TF-IDF pipeline\n",
        "with open('/content/drive/MyDrive/ML/pipeline_tfidf.pkl', 'rb') as file:\n",
        "    pipeline_tfidf = pickle.load(file)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_tfidf = pipeline_tfidf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(f\"TF-IDF Model Accuracy: {accuracy_tfidf:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
        "print(\"TF-IDF Confusion Matrix:\")\n",
        "print(conf_matrix_tfidf)\n",
        "\n",
        "# Classification report\n",
        "report_tfidf = classification_report(y_test, y_pred_tfidf)\n",
        "print(\"TF-IDF Classification Report:\")\n",
        "print(report_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ1FUf5-XbYV",
        "outputId": "13ad2496-b218-46ca-b3c4-962ac2a65924"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Model Accuracy: 0.70\n",
            "TF-IDF Confusion Matrix:\n",
            "[[  71  729]\n",
            " [   2 1598]]\n",
            "TF-IDF Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.09      0.16       800\n",
            "           1       0.69      1.00      0.81      1600\n",
            "\n",
            "    accuracy                           0.70      2400\n",
            "   macro avg       0.83      0.54      0.49      2400\n",
            "weighted avg       0.78      0.70      0.60      2400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/ML/all_kindle_review.csv\")\n",
        "df = dataset[['reviewText', 'rating']]\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Preprocessing\n",
        "df['rating'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)\n",
        "df['reviewText'] = df['reviewText'].str.lower()\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub('[^a-z A-Z 0-9-]+', '', x))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w_-]+(?:\\.[\\w_-]+)+[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-]?', '', x))\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], df['rating'], test_size=0.20, random_state=42, stratify=df['rating'])\n",
        "\n",
        "# Tokenize the text for Word2Vec\n",
        "X_train_tokens = [review.split() for review in X_train]\n",
        "X_test_tokens = [review.split() for review in X_test]\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to compute average Word2Vec for each review\n",
        "def compute_avg_w2v(tokens, model):\n",
        "    avg_vector = []\n",
        "    for review in tokens:\n",
        "        vectors = [model.wv[word] for word in review if word in model.wv]\n",
        "        if vectors:\n",
        "            avg_vector.append(sum(vectors) / len(vectors))\n",
        "        else:\n",
        "            avg_vector.append([0] * model.vector_size)\n",
        "    return avg_vector\n",
        "\n",
        "# Compute AvgWord2Vec for train and test data\n",
        "X_train_avg_w2v = compute_avg_w2v(X_train_tokens, w2v_model)\n",
        "X_test_avg_w2v = compute_avg_w2v(X_test_tokens, w2v_model)\n",
        "\n",
        "# Train a Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_avg_w2v, y_train)\n",
        "\n",
        "# Save the classifier and Word2Vec model\n",
        "with open('/content/drive/MyDrive/ML/classifier_avg_w2v.pkl', 'wb') as file:\n",
        "    pickle.dump(classifier, file)\n",
        "with open('/content/drive/MyDrive/ML/w2v_model.pkl', 'wb') as file:\n",
        "    pickle.dump(w2v_model, file)\n",
        "\n"
      ],
      "metadata": {
        "id": "NerSd1d1XiBt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the classifier and Word2Vec model\n",
        "with open('/content/drive/MyDrive/ML/classifier_avg_w2v.pkl', 'rb') as file:\n",
        "    classifier = pickle.load(file)\n",
        "with open('/content/drive/MyDrive/ML/w2v_model.pkl', 'rb') as file:\n",
        "    w2v_model = pickle.load(file)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_avg_w2v = classifier.predict(X_test_avg_w2v)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_avg_w2v = accuracy_score(y_test, y_pred_avg_w2v)\n",
        "print(f\"AvgWord2Vec Model Accuracy: {accuracy_avg_w2v:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix_avg_w2v = confusion_matrix(y_test, y_pred_avg_w2v)\n",
        "print(\"AvgWord2Vec Confusion Matrix:\")\n",
        "print(conf_matrix_avg_w2v)\n",
        "\n",
        "# Classification report\n",
        "report_avg_w2v = classification_report(y_test, y_pred_avg_w2v)\n",
        "print(\"AvgWord2Vec Classification Report:\")\n",
        "print(report_avg_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2vKRoXFalJx",
        "outputId": "803a15bb-23fb-4933-c725-fdf82e823562"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AvgWord2Vec Model Accuracy: 0.75\n",
            "AvgWord2Vec Confusion Matrix:\n",
            "[[ 372  428]\n",
            " [ 179 1421]]\n",
            "AvgWord2Vec Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.47      0.55       800\n",
            "           1       0.77      0.89      0.82      1600\n",
            "\n",
            "    accuracy                           0.75      2400\n",
            "   macro avg       0.72      0.68      0.69      2400\n",
            "weighted avg       0.74      0.75      0.73      2400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **BOW : 85 %**\n",
        "- **TF-IDF : 70%**\n",
        "- **AvgWord2Vec : 75%**\n"
      ],
      "metadata": {
        "id": "UWhJVoemb-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4MvIEp1bU46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}